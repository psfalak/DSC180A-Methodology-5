Pukhraj Falak, pfalak@ucsd.edu 
Section A10, Emily Raymond (mentor)

**What is the most interesting topic covered in your domain this quarter?**

The most interesting topic for me was an [article](https://www.brookings.edu/articles/why-new-york-city-is-cracking-down-on-ai-in-hiring/).  In the article, it talked about how New York was mandating annual bias audits for AI-driven hiring tools. The main purpose of this was to mitigate any potential biases that arise from automated employment decision-making. This was interesting for me because not only do I live in New York, but they are the only state right now that does this. I'd be curious to see what other states plan to adopt this in the future. 

**Describe a potential investigation you would like to pursue for your Quarter 2 Project.**

Our group is thinking about investigating different biases in social media. Specifically, we are looking to investigate any gender biases that are apparent in different social media `platforms (ex. Twitter ads), investigate why these biases are occurring, and mitigate the biases using methods we've learned. We also plan on using the AIF360 model to assist with the debiasing. Some of the questions we will be thinking about is what bias is being detected, why is it there, what is the real life impact on this kind of bias, and how can we fix it.

**What is a potential change youâ€™d make to the approach taken in your current Quarter 1 Project?**

I think one change I would make is to focus on one or two methods and try to optimize those methods. Right now, we learning a variety of different debiasing methods, which make sense given that we don't have a lot of experience with these techniques. However, next quarter, I think it's important to really optimize a few methods so we can get the best results rather than just doing so many different techniques. 

**What other techniques would you be interested in using in your project?** 

One technique I'd be interested in exploring is fair representation learning, which is essentially seeing new ways to process data that keep the important info but are less affected by  gender biases. An example of this could be adversarial deebiasing, since it could adjust the way we handle data to reduce the bias with ads on social media. 
